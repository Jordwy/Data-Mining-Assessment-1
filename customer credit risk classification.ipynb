{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74e8d175",
   "metadata": {},
   "source": [
    "## Explore, aggregate and transform the attributes (1.5 marks) \n",
    "- i. Write a Python script to read the input CSV file and perform any necessary pre-processing so that the data becomes suitable to be used.\n",
    "\n",
    "- ii.  Describe the pre-processing you carried out with justifications in your report.\n",
    "    \n",
    "\n",
    "    (Hint: Think about missing values and categorical attributes. \n",
    "    How to deal with them? \n",
    "    Should we turn them all into dummies? \n",
    "    Use only some? \n",
    "    Create new informative attributes by aggregating some attributes? \n",
    "    And so on.)\n",
    "\n",
    "- iii. Submit the pre-processed data in CSV format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56aa1e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444afe54",
   "metadata": {},
   "source": [
    "### Read CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51e2fdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = r'https://raw.githubusercontent.com/Jordwy/Data-Mining-Assessment-1/2bdb43446ec7dff44be25115218c017c9ab09b75/Assignment%201%20Data.csv'\n",
    "\n",
    "df = pd.read_csv(csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "496c56dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 19 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Default          1000 non-null   int64  \n",
      " 1   checkingstatus1  1000 non-null   object \n",
      " 2   duration         995 non-null    float64\n",
      " 3   history          996 non-null    object \n",
      " 4   purpose          987 non-null    object \n",
      " 5   amount           984 non-null    float64\n",
      " 6   savings          995 non-null    object \n",
      " 7   employ           990 non-null    object \n",
      " 8   status           993 non-null    object \n",
      " 9   others           994 non-null    object \n",
      " 10  residence        1000 non-null   int64  \n",
      " 11  property         992 non-null    object \n",
      " 12  age              998 non-null    float64\n",
      " 13  otherplans       1000 non-null   object \n",
      " 14  housing          994 non-null    object \n",
      " 15  cards            996 non-null    float64\n",
      " 16  job              991 non-null    object \n",
      " 17  liable           997 non-null    float64\n",
      " 18  foreign          988 non-null    object \n",
      "dtypes: float64(5), int64(2), object(12)\n",
      "memory usage: 148.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994c5c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Column Info and null count\\n\\n #   Column           Non-Null Count  Dtype  \\n---  ------           --------------  -----  \\n 0   Default          1000 non-null   int64         # class label\\n 1   checkingstatus1  1000 non-null   object        # No null\\n 2   duration         995 non-null    float64       # 5 nulls - replace with mean value\\n 3   history          996 non-null    object        # 4 null - remove them as assume this is important\\n 4   purpose          987 non-null    object        # 13 null - fill null with \\'A410\\' which means \"others\" as not sure important \\n 5   amount           984 non-null    float64       # 16 null - remove them as assume this is important\\n 6   savings          995 non-null    object        # 5 null - replace with \\'A65\\' which means \"unknown/no savings account\"\"unknown/no savings account\\n 7   employ           990 non-null    object        # 10 null - \\n 8   status           993 non-null    object        # 7 null -\\n 9   others           994 non-null    object        # 6 null - \\n 10  residence        1000 non-null   int64         # No null -\\n 11  property         992 non-null    object        # 8 null -\\n 12  age              998 non-null    float64       # 2 null -\\n 13  otherplans       1000 non-null   object        # No null -\\n 14  housing          994 non-null    object        # 6 null -\\n 15  cards            996 non-null    float64       # 4 null -\\n 16  job              991 non-null    object        # 9 null -\\n 17  liable           997 non-null    float64       # 3 null -\\n 18  foreign          988 non-null    object        # 12 null -\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' Column Info and null count\n",
    "\n",
    "    Review of how to handle each attribute when there are missing values\n",
    "\n",
    " #   Column           Non-Null Count  Dtype  \n",
    "---  ------           --------------  -----  \n",
    " 0   Default          1000 non-null   int64         # class label\n",
    " 1   checkingstatus1  1000 non-null   object        # No null\n",
    " 2   duration         995 non-null    float64       # 5 nulls - replace with mean value\n",
    " 3   history          996 non-null    object        # 4 null - remove them as assume this is important\n",
    " 4   purpose          987 non-null    object        # 13 null - fill null with 'A410' which means \"others\" as not sure important \n",
    " 5   amount           984 non-null    float64       # 16 null - remove them as assume this is important\n",
    " 6   savings          995 non-null    object        # 5 null - replace with 'A65' which means \"unknown/no savings account\"\"unknown/no savings account\n",
    " 7   employ           990 non-null    object        # 10 null - remove them as assume this is important\n",
    " 8   status           993 non-null    object        # 7 null - remove them as see no other appropriate way to fill\n",
    " 9   others           994 non-null    object        # 6 null - \n",
    " 10  residence        1000 non-null   int64         # No null -\n",
    " 11  property         992 non-null    object        # 8 null -\n",
    " 12  age              998 non-null    float64       # 2 null -\n",
    " 13  otherplans       1000 non-null   object        # No null -\n",
    " 14  housing          994 non-null    object        # 6 null -\n",
    " 15  cards            996 non-null    float64       # 4 null -\n",
    " 16  job              991 non-null    object        # 9 null -\n",
    " 17  liable           997 non-null    float64       # 3 null -\n",
    " 18  foreign          988 non-null    object        # 12 null -\n",
    "\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "df443904",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'count'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JLDwy\\OneDrive\\Uni - Data Science\\CSE5DMI - Data Mining\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'count'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mothers\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue_counts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdropna\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcount\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JLDwy\\OneDrive\\Uni - Data Science\\CSE5DMI - Data Mining\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1189\u001b[39m maybe_callable = com.apply_if_callable(key, \u001b[38;5;28mself\u001b[39m.obj)\n\u001b[32m   1190\u001b[39m maybe_callable = \u001b[38;5;28mself\u001b[39m._check_deprecated_callable_usage(key, maybe_callable)\n\u001b[32m-> \u001b[39m\u001b[32m1191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JLDwy\\OneDrive\\Uni - Data Science\\CSE5DMI - Data Mining\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1431\u001b[39m, in \u001b[36m_LocIndexer._getitem_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1429\u001b[39m \u001b[38;5;66;03m# fall thru to straight lookup\u001b[39;00m\n\u001b[32m   1430\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_key(key, axis)\n\u001b[32m-> \u001b[39m\u001b[32m1431\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JLDwy\\OneDrive\\Uni - Data Science\\CSE5DMI - Data Mining\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1381\u001b[39m, in \u001b[36m_LocIndexer._get_label\u001b[39m\u001b[34m(self, label, axis)\u001b[39m\n\u001b[32m   1379\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_label\u001b[39m(\u001b[38;5;28mself\u001b[39m, label, axis: AxisInt):\n\u001b[32m   1380\u001b[39m     \u001b[38;5;66;03m# GH#5567 this will fail if the label is not present in the axis.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1381\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mxs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JLDwy\\OneDrive\\Uni - Data Science\\CSE5DMI - Data Mining\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:4320\u001b[39m, in \u001b[36mNDFrame.xs\u001b[39m\u001b[34m(self, key, axis, level, drop_level)\u001b[39m\n\u001b[32m   4318\u001b[39m             new_index = index[loc]\n\u001b[32m   4319\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m4320\u001b[39m     loc = \u001b[43mindex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4322\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, np.ndarray):\n\u001b[32m   4323\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m loc.dtype == np.bool_:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\JLDwy\\OneDrive\\Uni - Data Science\\CSE5DMI - Data Mining\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'count'"
     ]
    }
   ],
   "source": [
    "df['others'].value_counts(dropna=False).loc['count']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
